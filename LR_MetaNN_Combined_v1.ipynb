{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34acf15f-aba0-4051-af3d-6a846baf18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_lr_vs_simple_meta.py\n",
    "# ------------------------------------------------------------\n",
    "# Apples-to-apples comparison: Logistic Regression vs simple_meta NN\n",
    "# - Same split\n",
    "# - Same preprocessing (numeric: impute+scale; categorical: impute+OHE)\n",
    "# - Same business objective threshold sweep\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# # tensorflow / keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab1d9b5-6a85-49e9-9ffd-df8663f8e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LR vs simple_meta NN: unified preprocessing, split, and business scoring ===\n",
      "Dataset: (255347, 17) | Default rate=11.613%\n",
      "Numeric: 9 | Categorical: 7\n",
      "\n",
      "=== PAYOFF DEBUG ===\n",
      "Assumptions: revenue_per_good=$16,250, loss_per_default=$23,040\n",
      "Break-even default probability (per approved): p*loss = (1-p)*revenue -> p* = 0.4136\n",
      "\n",
      "LoanAmount means by class (train+test):\n",
      "__y\n",
      "No Default    125353.656017\n",
      "Default       144515.311469\n",
      "Name: LoanAmount, dtype: float64\n",
      "\n",
      "InterestRate means by class (train+test):\n",
      "__y\n",
      "No Default    13.176994\n",
      "Default       15.896227\n",
      "Name: InterestRate, dtype: float64\n",
      "\n",
      "LR CV 5-fold | Acc: 0.8852 ± 0.0002 | F1: 0.0641 ± 0.0042\n",
      "\n",
      "Logistic Regression — Test @ threshold=0.50\n",
      "-------------------------------------------\n",
      "Accuracy:  0.8853 | Precision: 0.6084 | Recall: 0.0341 | F1: 0.0645 | ROC AUC: 0.7531\n",
      "Confusion  TN=45,009  FP=130  FN=5,729  TP=202\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No Default       0.89      1.00      0.94     45139\n",
      "     Default       0.61      0.03      0.06      5931\n",
      "\n",
      "    accuracy                           0.89     51070\n",
      "   macro avg       0.75      0.52      0.50     51070\n",
      "weighted avg       0.85      0.89      0.84     51070\n",
      "\n",
      "\n",
      "Logistic Regression — Business-optimal threshold\n",
      "------------------------------------------------\n",
      "Threshold: 0.3750 | Profit: $600,976,010\n",
      "Revenue:   $720,346,250 | Loss: $119,370,240\n",
      "Accuracy:  0.8827 | Precision: 0.4808 | Recall: 0.1265 | F1: 0.2002\n",
      "Confusion  TN=44,329  FP=810  FN=5,181  TP=750\n",
      "\n",
      "simple_meta NN — Test @ threshold=0.50\n",
      "--------------------------------------\n",
      "Accuracy:  0.8859 | Precision: 0.6585 | Recall: 0.0364 | F1: 0.0690 | ROC AUC: 0.7594\n",
      "Confusion  TN=45,027  FP=112  FN=5,715  TP=216\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No Default       0.89      1.00      0.94     45139\n",
      "     Default       0.66      0.04      0.07      5931\n",
      "\n",
      "    accuracy                           0.89     51070\n",
      "   macro avg       0.77      0.52      0.50     51070\n",
      "weighted avg       0.86      0.89      0.84     51070\n",
      "\n",
      "\n",
      "simple_meta NN — Business-optimal threshold\n",
      "-------------------------------------------\n",
      "Threshold: 0.3750 | Profit: $603,564,800\n",
      "Revenue:   $721,760,000 | Loss: $118,195,200\n",
      "Accuracy:  0.8854 | Precision: 0.5256 | Recall: 0.1351 | F1: 0.2149\n",
      "Confusion  TN=44,416  FP=723  FN=5,130  TP=801\n",
      "\n",
      "Logistic Regression — Approval stats @ business-optimal threshold\n",
      "Approvals: 49,510 (96.9% of test set)\n",
      "Default rate among approved (FN / approvals): 10.465%\n",
      "Revenue per approved: $14,550 | Loss per approved: $2,411\n",
      "\n",
      "simple_meta NN — Approval stats @ business-optimal threshold\n",
      "Approvals: 49,546 (97.0% of test set)\n",
      "Default rate among approved (FN / approvals): 10.354%\n",
      "Revenue per approved: $14,567 | Loss per approved: $2,386\n",
      "\n",
      "Logistic Regression — Profit sensitivity @ best threshold\n",
      "rev_mult  loss_mult   Revenue ($)     Loss ($)        Profit ($)\n",
      "    0.8       0.8    576,277,000     95,496,192    480,780,808\n",
      "    0.8       1.0    576,277,000    119,370,240    456,906,760\n",
      "    0.8       1.2    576,277,000    143,244,288    433,032,712\n",
      "\n",
      "    1.0       0.8    720,346,250     95,496,192    624,850,058\n",
      "    1.0       1.0    720,346,250    119,370,240    600,976,010\n",
      "    1.0       1.2    720,346,250    143,244,288    577,101,962\n",
      "\n",
      "    1.2       0.8    864,415,500     95,496,192    768,919,308\n",
      "    1.2       1.0    864,415,500    119,370,240    745,045,260\n",
      "    1.2       1.2    864,415,500    143,244,288    721,171,212\n",
      "\n",
      "\n",
      "simple_meta NN — Profit sensitivity @ best threshold\n",
      "rev_mult  loss_mult   Revenue ($)     Loss ($)        Profit ($)\n",
      "    0.8       0.8    577,408,000     94,556,160    482,851,840\n",
      "    0.8       1.0    577,408,000    118,195,200    459,212,800\n",
      "    0.8       1.2    577,408,000    141,834,240    435,573,760\n",
      "\n",
      "    1.0       0.8    721,760,000     94,556,160    627,203,840\n",
      "    1.0       1.0    721,760,000    118,195,200    603,564,800\n",
      "    1.0       1.2    721,760,000    141,834,240    579,925,760\n",
      "\n",
      "    1.2       0.8    866,112,000     94,556,160    771,555,840\n",
      "    1.2       1.0    866,112,000    118,195,200    747,916,800\n",
      "    1.2       1.2    866,112,000    141,834,240    724,277,760\n",
      "\n",
      "\n",
      "RANKING BY BUSINESS PERFORMANCE\n",
      "--------------------------------------------------------------------------------\n",
      "1. simple_meta NN       | Profit: $ 603,564,800 | Threshold: 0.3750 | Acc: 0.8854 | Prec: 0.5256 | Rec: 0.1351 | F1: 0.2149\n",
      "2. Logistic Regression  | Profit: $ 600,976,010 | Threshold: 0.3750 | Acc: 0.8827 | Prec: 0.4808 | Rec: 0.1265 | F1: 0.2002\n",
      "\n",
      "DELTA (simple_meta NN - LR) @ business-optimal for each model\n",
      "--------------------------------------------------------------------------------\n",
      "Profit delta:  $2,588,790\n",
      "Revenue delta: $1,413,750\n",
      "Loss delta:    $-1,175,040\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Config\n",
    "# ------------------------------------------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    csv_path: str = \"/Users/peekay/Downloads/Loan_default.csv\"\n",
    "    target: str = \"Default\"\n",
    "    drop_cols: Tuple[str, ...] = (\"LoanID\",)\n",
    "    test_size: float = 0.2\n",
    "    random_state: int = 42\n",
    "    cv_folds: int = 5\n",
    "\n",
    "    # Business economics (adjust as needed)\n",
    "    revenue_per_good: float = 125_000 * 0.13   # ~16,250\n",
    "    loss_per_default: float = 144_000 * 0.16   # ~23,040\n",
    "\n",
    "    # Threshold sweep grid\n",
    "    threshold_low: float = 0.05\n",
    "    threshold_high: float = 0.95\n",
    "    threshold_points: int = 37\n",
    "\n",
    "    # Logistic Regression hyperparams\n",
    "    lr_use_class_weight_balanced: bool = False\n",
    "    lr_solver: str = \"liblinear\"   # or \"lbfgs\"\n",
    "    lr_C: float = 1.0\n",
    "    lr_max_iter: int = 2000\n",
    "\n",
    "    # simple_meta NN hyperparams\n",
    "    nn_use_class_weight_balanced: bool = False\n",
    "    nn_epochs: int = 200          # << increased\n",
    "    nn_batch_size: int = 256\n",
    "    nn_val_split: float = 0.2\n",
    "    nn_patience: int = 12\n",
    "    nn_lr: float = 1e-3\n",
    "    nn_dropout: float = 0.3\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(CFG.random_state)\n",
    "tf.random.set_seed(CFG.random_state)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Data helpers\n",
    "# ------------------------------------------------------------\n",
    "def load_data(cfg: Config) -> pd.DataFrame:\n",
    "    df = pd.read_csv(cfg.csv_path)\n",
    "    for c in cfg.drop_cols:\n",
    "        if c in df.columns:\n",
    "            df = df.drop(columns=c)\n",
    "    return df\n",
    "\n",
    "def split_cols(df: pd.DataFrame, target: str) -> Tuple[pd.DataFrame, pd.Series, List[str], List[str]]:\n",
    "    y = df[target].astype(int)\n",
    "    X = df.drop(columns=target)\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "    return X, y, num_cols, cat_cols\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Preprocessing\n",
    "# ------------------------------------------------------------\n",
    "def make_numeric_preproc():\n",
    "    return Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "def make_categorical_preproc():\n",
    "    return Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "def fit_transform_preprocessors(X_train, X_test, num_cols, cat_cols):\n",
    "    num_pre = make_numeric_preproc()\n",
    "    cat_pre = make_categorical_preproc()\n",
    "    X_train_num = num_pre.fit_transform(X_train[num_cols])\n",
    "    X_test_num  = num_pre.transform(X_test[num_cols])\n",
    "    X_train_cat = cat_pre.fit_transform(X_train[cat_cols]) if len(cat_cols) > 0 else np.empty((len(X_train), 0))\n",
    "    X_test_cat  = cat_pre.transform(X_test[cat_cols]) if len(cat_cols) > 0 else np.empty((len(X_test), 0))\n",
    "    return num_pre, cat_pre, X_train_num, X_test_num, X_train_cat, X_test_cat\n",
    "\n",
    "def build_lr_preprocessor(num_cols, cat_cols):\n",
    "    return ColumnTransformer([\n",
    "        (\"num\", make_numeric_preproc(), num_cols),\n",
    "        (\"cat\", make_categorical_preproc(), cat_cols)\n",
    "    ])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Models\n",
    "# ------------------------------------------------------------\n",
    "def build_logistic_regression(cfg: Config) -> LogisticRegression:\n",
    "    class_weight = \"balanced\" if cfg.lr_use_class_weight_balanced else None\n",
    "    return LogisticRegression(\n",
    "        solver=cfg.lr_solver,\n",
    "        C=cfg.lr_C,\n",
    "        max_iter=cfg.lr_max_iter,\n",
    "        class_weight=class_weight,\n",
    "        n_jobs=None if cfg.lr_solver == \"liblinear\" else -1,\n",
    "        random_state=cfg.random_state\n",
    "    )\n",
    "\n",
    "def build_simple_meta_nn(num_dim: int, cat_dim: int, cfg: Config) -> Model:\n",
    "    in_num = Input(shape=(num_dim,), name=\"num_input\")\n",
    "    x_num = Dense(64, activation=\"relu\")(in_num)\n",
    "    x_num = Dropout(cfg.nn_dropout)(x_num)\n",
    "    x_num = Dense(32, activation=\"relu\")(x_num)\n",
    "\n",
    "    in_cat = Input(shape=(cat_dim,), name=\"cat_input\")\n",
    "    x_cat = Dense(64, activation=\"relu\")(in_cat)\n",
    "    x_cat = Dropout(cfg.nn_dropout)(x_cat)\n",
    "    x_cat = Dense(32, activation=\"relu\")(x_cat)\n",
    "\n",
    "    fused = Concatenate(name=\"fuse\")([x_num, x_cat])\n",
    "    z = Dense(32, activation=\"relu\")(fused)\n",
    "    z = Dropout(cfg.nn_dropout)(z)\n",
    "    z = Dense(16, activation=\"relu\")(z)\n",
    "    out = Dense(1, activation=\"sigmoid\", name=\"default_risk\")(z)\n",
    "\n",
    "    model = Model(inputs=[in_num, in_cat], outputs=out, name=\"simple_meta\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=cfg.nn_lr),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Business scoring\n",
    "# ------------------------------------------------------------\n",
    "def business_eval(y_true: np.ndarray,\n",
    "                  y_prob: np.ndarray,\n",
    "                  threshold: float,\n",
    "                  revenue_per_good: float,\n",
    "                  loss_per_default: float) -> Dict:\n",
    "    # y_pred==1 => decline; y_pred==0 => approve\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    revenue = tn * revenue_per_good\n",
    "    loss = fn * loss_per_default\n",
    "    profit = revenue - loss\n",
    "    return dict(\n",
    "        threshold=threshold, tn=tn, fp=fp, fn=fn, tp=tp,\n",
    "        precision=precision_score(y_true, y_pred, zero_division=0),\n",
    "        recall=recall_score(y_true, y_pred, zero_division=0),\n",
    "        f1=f1_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy=accuracy_score(y_true, y_pred),\n",
    "        revenue=revenue, loss=loss, profit=profit\n",
    "    )\n",
    "\n",
    "def sweep_thresholds(y_true: np.ndarray,\n",
    "                     y_prob: np.ndarray,\n",
    "                     low: float, high: float, points: int,\n",
    "                     revenue_per_good: float, loss_per_default: float):\n",
    "    thresholds = np.linspace(low, high, points)\n",
    "    grid = [business_eval(y_true, y_prob, t, revenue_per_good, loss_per_default) for t in thresholds]\n",
    "    best = max(grid, key=lambda r: r[\"profit\"])\n",
    "    return best, grid\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Debug: payoff checks & sensitivity\n",
    "# ------------------------------------------------------------\n",
    "def print_payoff_debug(df_all: pd.DataFrame, y: pd.Series, cfg: Config):\n",
    "    print(\"\\n=== PAYOFF DEBUG ===\")\n",
    "    rev = cfg.revenue_per_good\n",
    "    loss = cfg.loss_per_default\n",
    "    print(f\"Assumptions: revenue_per_good=${rev:,.0f}, loss_per_default=${loss:,.0f}\")\n",
    "    be_pd = rev / (rev + loss) if (rev + loss) > 0 else np.nan\n",
    "    print(f\"Break-even default probability (per approved): p*loss = (1-p)*revenue -> p* = {be_pd:.4f}\")\n",
    "\n",
    "    cols = df_all.columns\n",
    "    cols_lower = [c.lower() for c in cols]\n",
    "    has_amt = \"loanamount\" in cols_lower\n",
    "    has_rate = \"interestrate\" in cols_lower\n",
    "\n",
    "    def safe_col(name_lower):\n",
    "        idx = cols_lower.index(name_lower)\n",
    "        return cols[idx]\n",
    "\n",
    "    if has_amt or has_rate:\n",
    "        tmp = df_all.copy()\n",
    "        tmp[\"__y\"] = y.values\n",
    "        if has_amt:\n",
    "            la = safe_col(\"loanamount\")\n",
    "            print(\"\\nLoanAmount means by class (train+test):\")\n",
    "            print(tmp.groupby(\"__y\")[la].mean().rename({0:\"No Default\",1:\"Default\"}))\n",
    "        if has_rate:\n",
    "            ir = safe_col(\"interestrate\")\n",
    "            print(\"\\nInterestRate means by class (train+test):\")\n",
    "            print(tmp.groupby(\"__y\")[ir].mean().rename({0:\"No Default\",1:\"Default\"}))\n",
    "    else:\n",
    "        print(\"Note: Could not find LoanAmount/InterestRate columns for sanity check.\")\n",
    "\n",
    "def print_threshold_debug(name: str, best: Dict):\n",
    "    approvals = best[\"tn\"] + best[\"fn\"]\n",
    "    approved_default_rate = (best[\"fn\"] / approvals) if approvals > 0 else 0.0\n",
    "    print(f\"\\n{name} — Approval stats @ business-optimal threshold\")\n",
    "    print(f\"Approvals: {approvals:,} ({approvals / (best['tn'] + best['fp'] + best['fn'] + best['tp']):.1%} of test set)\")\n",
    "    print(f\"Default rate among approved (FN / approvals): {approved_default_rate:.3%}\")\n",
    "    denom = approvals if approvals > 0 else 1\n",
    "    print(f\"Revenue per approved: ${best['revenue']/denom:,.0f} | Loss per approved: ${best['loss']/denom:,.0f}\")\n",
    "\n",
    "def sensitivity_table(name: str, best: Dict, cfg: Config):\n",
    "    # Evaluate profit sensitivity at model's best threshold under +/-20% payoff multipliers\n",
    "    rev0, loss0 = cfg.revenue_per_good, cfg.loss_per_default\n",
    "    tn, fn = best[\"tn\"], best[\"fn\"]\n",
    "    print(f\"\\n{name} — Profit sensitivity @ best threshold\")\n",
    "    print(\"rev_mult  loss_mult   Revenue ($)     Loss ($)        Profit ($)\")\n",
    "    for rev_mult in [0.8, 1.0, 1.2]:\n",
    "        for loss_mult in [0.8, 1.0, 1.2]:\n",
    "            revenue = tn * rev0 * rev_mult\n",
    "            loss = fn * loss0 * loss_mult\n",
    "            profit = revenue - loss\n",
    "            print(f\"{rev_mult:7.1f}  {loss_mult:8.1f}   {revenue:12,.0f}   {loss:12,.0f}   {profit:12,.0f}\")\n",
    "        print()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Utilities\n",
    "# ------------------------------------------------------------\n",
    "def print_metrics_header(title: str):\n",
    "    print(\"\\n\" + title)\n",
    "    print(\"-\" * len(title))\n",
    "\n",
    "def print_summary_block(name: str, prob, y_test, cfg: Config):\n",
    "    # Default 0.50\n",
    "    y_pred = (prob >= 0.5).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "\n",
    "    print_metrics_header(f\"{name} — Test @ threshold=0.50\")\n",
    "    print(f\"Accuracy:  {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | ROC AUC: {auc:.4f}\")\n",
    "    print(f\"Confusion  TN={tn:,}  FP={fp:,}  FN={fn:,}  TP={tp:,}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"No Default\",\"Default\"]))\n",
    "\n",
    "    best, grid = sweep_thresholds(y_test, prob,\n",
    "                                  CFG.threshold_low, CFG.threshold_high, CFG.threshold_points,\n",
    "                                  CFG.revenue_per_good, CFG.loss_per_default)\n",
    "    print_metrics_header(f\"{name} — Business-optimal threshold\")\n",
    "    print(f\"Threshold: {best['threshold']:.4f} | Profit: ${best['profit']:,.0f}\")\n",
    "    print(f\"Revenue:   ${best['revenue']:,.0f} | Loss: ${best['loss']:,.0f}\")\n",
    "    print(f\"Accuracy:  {best['accuracy']:.4f} | Precision: {best['precision']:.4f} | Recall: {best['recall']:.4f} | F1: {best['f1']:.4f}\")\n",
    "    print(f\"Confusion  TN={best['tn']:,}  FP={best['fp']:,}  FN={best['fn']:,}  TP={best['tp']:,}\")\n",
    "    return best\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main\n",
    "# ------------------------------------------------------------\n",
    "def main(cfg: Config):\n",
    "    print(\"=== LR vs simple_meta NN: unified preprocessing, split, and business scoring ===\")\n",
    "    df = load_data(cfg)\n",
    "    X, y, num_cols, cat_cols = split_cols(df, cfg.target)\n",
    "    print(f\"Dataset: {df.shape} | Default rate={y.mean():.3%}\")\n",
    "    print(f\"Numeric: {len(num_cols)} | Categorical: {len(cat_cols)}\")\n",
    "\n",
    "    # One stratified split reused by BOTH models\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=cfg.test_size, random_state=cfg.random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Debug: payoff sanity check against raw columns\n",
    "    print_payoff_debug(pd.concat([X_train, X_test], axis=0), pd.concat([y_train, y_test], axis=0), cfg)\n",
    "\n",
    "    # Fit separate preprocessors for numeric and categorical (for NN inputs)\n",
    "    num_pre, cat_pre, Xtr_num, Xte_num, Xtr_cat, Xte_cat = fit_transform_preprocessors(\n",
    "        X_train, X_test, num_cols, cat_cols\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Logistic Regression\n",
    "    # -----------------------------\n",
    "    lr_pre = build_lr_preprocessor(num_cols, cat_cols)\n",
    "    lr = build_logistic_regression(cfg)\n",
    "    lr_pipe = Pipeline([(\"pre\", lr_pre), (\"clf\", lr)])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cfg.cv_folds, shuffle=True, random_state=cfg.random_state)\n",
    "    cv_acc = cross_val_score(lr_pipe, X_train, y_train, cv=skf, scoring=\"accuracy\")\n",
    "    cv_f1  = cross_val_score(lr_pipe, X_train, y_train, cv=skf, scoring=\"f1\")\n",
    "    print(f\"\\nLR CV {cfg.cv_folds}-fold | Acc: {cv_acc.mean():.4f} ± {cv_acc.std():.4f} | F1: {cv_f1.mean():.4f} ± {cv_f1.std():.4f}\")\n",
    "\n",
    "    lr_pipe.fit(X_train, y_train)\n",
    "    lr_prob = lr_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # -----------------------------\n",
    "    # simple_meta NN\n",
    "    # -----------------------------\n",
    "    num_dim, cat_dim = Xtr_num.shape[1], Xtr_cat.shape[1]\n",
    "    simple_meta = build_simple_meta_nn(num_dim, cat_dim, cfg)\n",
    "\n",
    "    cw = None\n",
    "    if cfg.nn_use_class_weight_balanced:\n",
    "        classes = np.unique(y_train)\n",
    "        counts = np.bincount(y_train)\n",
    "        total = counts.sum()\n",
    "        cw = {cls: total / (len(classes) * counts[cls]) for cls in classes}\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=cfg.nn_patience, restore_best_weights=True, verbose=0)\n",
    "    _ = simple_meta.fit(\n",
    "        [Xtr_num, Xtr_cat], y_train.values,\n",
    "        epochs=cfg.nn_epochs,\n",
    "        batch_size=cfg.nn_batch_size,\n",
    "        validation_split=cfg.nn_val_split,\n",
    "        callbacks=[es],\n",
    "        class_weight=cw,\n",
    "        verbose=0\n",
    "    )\n",
    "    nn_prob = simple_meta.predict([Xte_num, Xte_cat], verbose=0).ravel()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Reports (common scoring)\n",
    "    # -----------------------------\n",
    "    best_lr = print_summary_block(\"Logistic Regression\", lr_prob, y_test.values, cfg)\n",
    "    best_nn = print_summary_block(\"simple_meta NN\", nn_prob, y_test.values, cfg)\n",
    "\n",
    "    # Extra debug on approvals at best thresholds\n",
    "    print_threshold_debug(\"Logistic Regression\", best_lr)\n",
    "    print_threshold_debug(\"simple_meta NN\", best_nn)\n",
    "\n",
    "    # Sensitivity (±20% payoff multipliers) at each model's best threshold\n",
    "    sensitivity_table(\"Logistic Regression\", best_lr, cfg)\n",
    "    sensitivity_table(\"simple_meta NN\", best_nn, cfg)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Head-to-head leaderboard\n",
    "    # -----------------------------\n",
    "    print(\"\\nRANKING BY BUSINESS PERFORMANCE\")\n",
    "    print(\"-\" * 80)\n",
    "    rows = [\n",
    "        (\"Logistic Regression\", best_lr[\"profit\"], best_lr[\"threshold\"],\n",
    "         best_lr[\"accuracy\"], best_lr[\"precision\"], best_lr[\"recall\"], best_lr[\"f1\"]),\n",
    "        (\"simple_meta NN\", best_nn[\"profit\"], best_nn[\"threshold\"],\n",
    "         best_nn[\"accuracy\"], best_nn[\"precision\"], best_nn[\"recall\"], best_nn[\"f1\"]),\n",
    "    ]\n",
    "    rows_sorted = sorted(rows, key=lambda r: r[1], reverse=True)\n",
    "    for i, r in enumerate(rows_sorted, 1):\n",
    "        print(f\"{i}. {r[0]:20s} | Profit: ${r[1]:>12,.0f} | Threshold: {r[2]:.4f} | \"\n",
    "              f\"Acc: {r[3]:.4f} | Prec: {r[4]:.4f} | Rec: {r[5]:.4f} | F1: {r[6]:.4f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Delta (REVERSED): simple_meta NN - LR\n",
    "    # -----------------------------\n",
    "    print(\"\\nDELTA (simple_meta NN - LR) @ business-optimal for each model\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Profit delta:  ${best_nn['profit'] - best_lr['profit']:,.0f}\")\n",
    "    print(f\"Revenue delta: ${best_nn['revenue'] - best_lr['revenue']:,.0f}\")\n",
    "    print(f\"Loss delta:    ${best_nn['loss'] - best_lr['loss']:,.0f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(CFG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743998a-f3ee-463f-b6dc-c9ecfbe28891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Meta Learning (.venv)",
   "language": "python",
   "name": "meta_learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
